---
title: "Modeling"
author: "Alex Kan -lexokan"
date: "April 14, 2018"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(stringr)
library(data.table)

library(e1071)
library(tree)

library(MASS)
librar(ROCR)

set.seed(1)
```

```{r}
df <- read.csv("data/phoenix.csv")
temp <- df

```

PCA:
```{r}
temp$yelpingSince <- as.Date(temp$yelpingSince)
temp$date <- as.Date(temp$date)

temp <- temp %>% 
    select(-c(date, yelpingSince, userID, businessID, reviewID, businessName, city))
pca <- prcomp(temp)

biplot(pca)
```

SVM: 
```{r}
svm.mod <- svm(data = temp, reviewStars~., kernel = "linear", scale = F, cost = .1)
```
Decision Trees: 
```{r}
tree.mod <- tree(data = temp, reviewStars~.)
```

Logistic Regression
```{r}

```

# Quadratic Discriminant Analysis

Quadratic Discriminant Analysis allows for non-linear (quadratic) decision boundaries, unlike Linear Discimrinant Analysis. QDA require the number of predictor variables (p) to be less then the sample size (n). We are assuming predictor variables X are drawn from a multivariate Gaussian (aka normal) distribution and that the covariance matrix can be different for each class so we must estimate the covariance matrix separately for each class. However, QDA is recommended if the training set is very large, so that the variance of the classifier is not a major concern, or if the assumption of a common covariance matrix is clearly untenable.

First, we will define a binary variable for averageReviewBusiness. Ratings greater than 3 are considered good ratings and ratings below 3 are bad ratings.

We will create the training and test sets(80%/20%).

Now, we will run QDA and look at the test MSE (mean squared error).
```{r}
az <- read.csv("data/phoenixAg.csv")
az$rate <- ifelse(az$averageReviewBusiness < 2, 0,1)

#Create Train & Test Sets
train <- sample(1:(0.80*nrow(az)),replace=FALSE)
az.train <- az[train,]
az.test <- az[-train,]
```

```{r}
qda.fit <- qda(rate~reviewCountBusiness, data = az.train)
qda.fit

#predict
qda.predict <- predict(qda.fit, newdata=az.test)
qda.class <- qda.predict$class
#Confusion matrix
table(qda.class,az.test$rate)

#Overall fraction of incorrect test predictions (MSE: mean squared error)
mean(qda.class != az.test$rate)
```

```{r, echo=FALSE}
qda.p <- prediction(qda.predict$posterior[,2], az.test$rate) %>%
  performance(measure = "tpr", x.measure = "fpr")

plot(qda.p, col = "red")

#QDA AUC
prediction(qda.predict$posterior[,2], az.test$rate) %>%
  performance(measure = "auc") %>%
  .@y.values
```

